{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOw+Ta+tpOI47STZ2cw2cZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShovalBenjer/deep_learning_neural_networks/blob/main/Deep_exc_2_adir_shoval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TL;DR:**\n",
        "\n",
        "**Collaborators: Shoval Benjer 319037404, Adir Amar 209017755**"
      ],
      "metadata": {
        "id": "4v5p7MnNcqZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **setup:**\n",
        "\n",
        "\n",
        "To run this code, you'll need the following requirements:\n",
        "\n",
        "Python 3.x\n",
        "\n",
        "PyTorch\n",
        "\n",
        "NumPy\n",
        "\n",
        "Pandas\n",
        "\n",
        "You can install these requirements using pip:\n",
        "\n",
        "`!pip install torch numpy pandas`\n",
        "\n",
        "To run the code:\n",
        "\n",
        "1. Copy the provided code into a Python file (e.g., xor_network.py)\n",
        "2. Run the file using Python:\n",
        "`python xor_network.py`\n",
        "\n",
        "If you need to run this in VLab:\n",
        "Log in to your VLab account\n",
        "Open a terminal\n",
        "**Ensure the required packages are installed** (use the pip command above if needed)\n",
        "Navigate to the directory containing your Python file\n",
        "Run the file using Python as described above\n",
        "The code will automatically run experiments for k=1 (with bypass), k=2, and k=4, displaying the weights, biases, loss values, and truth tables for each configuration.\n",
        "\n",
        "Note: The code uses a low temperature (0.001) for the BTU/sigmoid function as requested in the assignment. No additional setup is required beyond having the necessary Python packages installed."
      ],
      "metadata": {
        "id": "IQg-LYwlx0cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch seaborn matplotlib"
      ],
      "metadata": {
        "id": "oc494TvfoKhw",
        "outputId": "90ecd8c0-0bd1-485b-98b2-57e86bf2bb6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Pn4So9pxnDnL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datasets():\n",
        "    \"\"\"\n",
        "    Creates the training and validation sets for the XOR problem.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_x, train_y, val_x, val_y) all as torch.FloatTensors.\n",
        "    \"\"\"\n",
        "    train_x = torch.tensor([[0., 0.],\n",
        "                            [0., 1.],\n",
        "                            [1., 0.],\n",
        "                            [1., 1.]], dtype=torch.float32)\n",
        "    train_y = torch.tensor([[0.],\n",
        "                            [1.],\n",
        "                            [1.],\n",
        "                            [0.]], dtype=torch.float32)\n",
        "\n",
        "    val_x = torch.tensor([[0.,0.],\n",
        "                          [0.,1.],\n",
        "                          [1.,0.],\n",
        "                          [1.,1.],\n",
        "                          [1.,0.1],\n",
        "                          [1.,0.9],\n",
        "                          [0.9,0.9],\n",
        "                          [0.1,0.9]], dtype=torch.float32)\n",
        "    val_y = torch.tensor([[0.],\n",
        "                          [1.],\n",
        "                          [1.],\n",
        "                          [0.],\n",
        "                          [1.],\n",
        "                          [0.],\n",
        "                          [0.],\n",
        "                          [1.]], dtype=torch.float32)\n",
        "    return train_x, train_y, val_x, val_y\n",
        "\n",
        "class Network(nn.Module):\n",
        "    \"\"\"\n",
        "    A small neural network class for learning the XOR function.\n",
        "    Can optionally include a bypass connection from inputs to output layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size: int, bypass: bool = False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size (int): Number of hidden neurons.\n",
        "            bypass (bool): If True, output layer receives original input as well.\n",
        "        \"\"\"\n",
        "        super(Network, self).__init__()\n",
        "        self.bypass = bypass\n",
        "        self.hidden = nn.Linear(2, hidden_size)\n",
        "        output_input_dim = hidden_size + (2 if bypass else 0)\n",
        "        self.output = nn.Linear(output_input_dim, 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input data of shape (batch_size, 2).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Model predictions of shape (batch_size, 1).\n",
        "        \"\"\"\n",
        "        h = self.activation(self.hidden(x))\n",
        "        if self.bypass:\n",
        "            h = torch.cat((x, h), dim=1)\n",
        "        return self.activation(self.output(h))\n",
        "\n",
        "def train_model(model: nn.Module, train_x: torch.Tensor, train_y: torch.Tensor,\n",
        "                val_x: torch.Tensor, val_y: torch.Tensor, lr: float,\n",
        "                max_epochs: int = 40000, patience: int = 10,\n",
        "                improvement_threshold: float = 0.0001, val_loss_goal: float = 0.2) -> tuple:\n",
        "    \"\"\"\n",
        "    Trains the given model until one of the specified stop conditions is met.\n",
        "\n",
        "    Stop conditions:\n",
        "    1. Validation loss not improved by more than `improvement_threshold` in `patience` consecutive epochs\n",
        "       AND best validation loss < val_loss_goal => success\n",
        "    2. If `max_epochs` reached without success => fail\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network to train.\n",
        "        train_x (torch.Tensor): Training inputs.\n",
        "        train_y (torch.Tensor): Training targets.\n",
        "        val_x (torch.Tensor): Validation inputs.\n",
        "        val_y (torch.Tensor): Validation targets.\n",
        "        lr (float): Learning rate.\n",
        "        max_epochs (int): Maximum number of epochs allowed.\n",
        "        patience (int): Number of epochs to wait for improvement.\n",
        "        improvement_threshold (float): Minimum improvement to reset patience.\n",
        "        val_loss_goal (float): Validation loss goal for success.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (success (bool), epochs (int), final_train_loss (float), final_val_loss (float))\n",
        "    \"\"\"\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    success = False\n",
        "    epoch = 0\n",
        "\n",
        "    while epoch < max_epochs:\n",
        "        epoch += 1\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(train_x)\n",
        "        train_loss = loss_fn(y_pred, train_y)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(val_x)\n",
        "            val_loss = loss_fn(val_pred, val_y).item()\n",
        "\n",
        "        if val_loss < best_val_loss - improvement_threshold:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience and best_val_loss < val_loss_goal:\n",
        "            success = True\n",
        "            break\n",
        "\n",
        "    return success, epoch, train_loss.item(), val_loss\n",
        "\n",
        "def run_experiment(lr: float, hidden: int, bypass: bool, n_successes: int = 10) -> dict:\n",
        "    \"\"\"\n",
        "    Runs multiple trials of the XOR training with given parameters until `n_successes` successful runs are obtained.\n",
        "    Tracks and aggregates statistics from successful runs.\n",
        "\n",
        "    Args:\n",
        "        lr (float): Learning rate.\n",
        "        hidden (int): Number of hidden neurons.\n",
        "        bypass (bool): Whether to use bypass connection.\n",
        "        n_successes (int): Number of successful runs required.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with computed statistics and details of runs.\n",
        "    \"\"\"\n",
        "    train_x, train_y, val_x, val_y = create_datasets()\n",
        "\n",
        "    successes = 0\n",
        "    fail_count = 0\n",
        "    epochs_list = []\n",
        "    train_losses_list = []\n",
        "    val_losses_list = []\n",
        "    models_list = []\n",
        "\n",
        "    while successes < n_successes:\n",
        "        model = Network(hidden, bypass)\n",
        "        success, epochs, train_l, val_l = train_model(\n",
        "            model, train_x, train_y, val_x, val_y, lr=lr)\n",
        "\n",
        "        if success:\n",
        "            successes += 1\n",
        "            epochs_list.append(epochs)\n",
        "            train_losses_list.append(train_l)\n",
        "            val_losses_list.append(val_l)\n",
        "            models_list.append(model)\n",
        "        else:\n",
        "            fail_count += 1\n",
        "\n",
        "    mean_epochs = statistics.mean(epochs_list)\n",
        "    std_epochs_percent = (statistics.pstdev(epochs_list) * 100 / mean_epochs) if len(epochs_list) > 1 else 0\n",
        "    mean_train_loss = statistics.mean(train_losses_list)\n",
        "    std_train_loss = statistics.pstdev(train_losses_list) if len(train_losses_list) > 1 else 0\n",
        "    mean_val_loss = statistics.mean(val_losses_list)\n",
        "    std_val_loss = statistics.pstdev(val_losses_list) if len(val_losses_list) > 1 else 0\n",
        "\n",
        "    return {\n",
        "        'lr': lr,\n",
        "        'hidden': hidden,\n",
        "        'bypass': bypass,\n",
        "        'mean_epochs': mean_epochs,\n",
        "        'std_epochs_%': std_epochs_percent,\n",
        "        'mean_train_loss': mean_train_loss,\n",
        "        'std_train_loss': std_train_loss,\n",
        "        'mean_val_loss': mean_val_loss,\n",
        "        'std_val_loss': std_val_loss,\n",
        "        'fail_count': fail_count,\n",
        "        'models': models_list\n",
        "    }\n",
        "\n",
        "def print_experiment_results(result: dict):\n",
        "    \"\"\"\n",
        "    Prints experiment results in a structured format.\n",
        "\n",
        "    Args:\n",
        "        result (dict): Result dictionary from run_experiment().\n",
        "    \"\"\"\n",
        "    print(\"=== Experiment Results ===\")\n",
        "    print(f\"Params: LR={result['lr']}, Hidden={result['hidden']}, Bypass={result['bypass']}\")\n",
        "    print(f\"Mean epochs: {result['mean_epochs']:.2f} (std %: {result['std_epochs_%']:.2f}%)\")\n",
        "    print(f\"Mean Train Loss: {result['mean_train_loss']:.4f} (std: {result['std_train_loss']:.4f})\")\n",
        "    print(f\"Mean Val Loss: {result['mean_val_loss']:.4f} (std: {result['std_val_loss']:.4f})\")\n",
        "    print(f\"Failed runs until 10 successes: {result['fail_count']}\")\n",
        "    print(\"==========================================\\n\")\n",
        "\n",
        "def print_hidden_outputs(model: nn.Module, train_x: torch.Tensor, train_y: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Prints the hidden neuron outputs for the training set inputs.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        train_x (torch.Tensor): Training input features.\n",
        "        train_y (torch.Tensor): Training targets.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        h = model.activation(model.hidden(train_x))\n",
        "        print(\"Hidden neuron outputs:\")\n",
        "        for i, inp in enumerate(train_x):\n",
        "            print(f\"Input: {inp.tolist()}, Hidden: {h[i].tolist()}, Target: {train_y[i].item()}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run all experiments as required and print results.\n",
        "    \"\"\"\n",
        "    experiment_params = [\n",
        "        (0.1, 2, False),\n",
        "        (0.1, 2, True),\n",
        "        (0.1, 4, False),\n",
        "        (0.1, 4, True),\n",
        "        (0.01, 2, False),\n",
        "        (0.01, 2, True),\n",
        "        (0.01, 4, False),\n",
        "        (0.01, 4, True),\n",
        "        (1.0, 1, True)\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for i, (lr, hidden, bypass) in enumerate(experiment_params):\n",
        "        result = run_experiment(lr, hidden, bypass)\n",
        "        print_experiment_results(result)\n",
        "        results.append(result)\n",
        "\n",
        "    exp9 = results[-1]\n",
        "    train_x, train_y, _, _ = create_datasets()\n",
        "    model9 = exp9['models'][0]\n",
        "    print(\"=== Experiment 9 Hidden Layer Analysis ===\")\n",
        "    print_hidden_outputs(model9, train_x, train_y)\n",
        "    exp_data = results[:-1]\n",
        "    hidden2 = [res for res in exp_data if res['hidden'] == 2]\n",
        "    hidden4 = [res for res in exp_data if res['hidden'] == 4]\n",
        "    mean_epochs_h2 = np.mean([r['mean_epochs'] for r in hidden2])\n",
        "    mean_epochs_h4 = np.mean([r['mean_epochs'] for r in hidden4])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.bar(['Hidden=2','Hidden=4'], [mean_epochs_h2, mean_epochs_h4])\n",
        "    plt.title('Mean Epochs Until Stopping by Hidden Units')\n",
        "    plt.ylabel('Mean Epochs')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vgM5m6U9iId-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "W6mPpFP_iJxz",
        "outputId": "9526d5bf-305f-4089-9626-caee50304704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Experiment Results ===\n",
            "Params: LR=0.1, Hidden=2, Bypass=False\n",
            "Mean epochs: 11327.70 (std %: 35.78%)\n",
            "Mean Train Loss: 0.0301 (std: 0.0043)\n",
            "Mean Val Loss: 0.0408 (std: 0.0051)\n",
            "Failed runs until 10 successes: 0\n",
            "==========================================\n",
            "\n",
            "=== Experiment Results ===\n",
            "Params: LR=0.1, Hidden=2, Bypass=True\n",
            "Mean epochs: 11702.50 (std %: 15.25%)\n",
            "Mean Train Loss: 0.0391 (std: 0.0051)\n",
            "Mean Val Loss: 0.0554 (std: 0.0077)\n",
            "Failed runs until 10 successes: 0\n",
            "==========================================\n",
            "\n",
            "=== Experiment Results ===\n",
            "Params: LR=0.1, Hidden=4, Bypass=False\n",
            "Mean epochs: 9562.20 (std %: 22.51%)\n",
            "Mean Train Loss: 0.0267 (std: 0.0018)\n",
            "Mean Val Loss: 0.0373 (std: 0.0026)\n",
            "Failed runs until 10 successes: 0\n",
            "==========================================\n",
            "\n",
            "=== Experiment Results ===\n",
            "Params: LR=0.1, Hidden=4, Bypass=True\n",
            "Mean epochs: 9424.20 (std %: 14.31%)\n",
            "Mean Train Loss: 0.0312 (std: 0.0059)\n",
            "Mean Val Loss: 0.0461 (std: 0.0078)\n",
            "Failed runs until 10 successes: 0\n",
            "==========================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}