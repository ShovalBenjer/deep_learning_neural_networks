{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx+rF05Wxn0eRaTBDrg/uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShovalBenjer/deep_learning_neural_networks/blob/main/Deep_exc_1_adir_shoval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tIs_bVMxKaYK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class BTU(nn.Module):\n",
        "    def __init__(self, T=0.01):\n",
        "        super(BTU, self).__init__()\n",
        "        self.T = T\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return 1 / (1 + torch.exp(-input / self.T))\n",
        "\n",
        "class LogisticNeuralNetwork(nn.Module):\n",
        "    def __init__(self, k, bypass=False):\n",
        "        super(LogisticNeuralNetwork, self).__init__()\n",
        "        self.k = k\n",
        "        self.bypass = bypass\n",
        "        self.hidden = nn.Linear(2, k)\n",
        "        self.output = nn.Linear(k + (2 if bypass else 0), 1)\n",
        "        self.activation = BTU()\n",
        "\n",
        "    def weights_set(self, w, b, layer_name):\n",
        "        layer = getattr(self, layer_name)\n",
        "        if w.shape != layer.weight.data.shape or b.shape != layer.bias.data.shape:\n",
        "            raise ValueError(f\"Error: Dimensions do not match for {layer_name}\")\n",
        "        with torch.no_grad():\n",
        "            layer.weight = nn.Parameter(w)\n",
        "            layer.bias = nn.Parameter(b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.activation(self.hidden(x))\n",
        "        if self.bypass:\n",
        "            h = torch.cat((h, x), dim=1)\n",
        "        return self.activation(self.output(h))\n",
        "\n",
        "def loss_fn(predicted, actual):\n",
        "    return torch.sum((predicted - actual) ** 2) / predicted.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "y = torch.FloatTensor([[0.], [1.], [1.], [0.]])\n",
        "\n",
        "for k in [1, 2, 4]:\n",
        "    print(f\"\\nk = {k}\")\n",
        "    bypass = k == 1\n",
        "    model = LogisticNeuralNetwork(k, bypass)\n",
        "\n",
        "    if k == 1:\n",
        "        model.weights_set(torch.tensor([[20., -20.]]), torch.tensor([-10.]), 'hidden')\n",
        "        model.weights_set(torch.tensor([[20., 20., 20.]]), torch.tensor([-30.]), 'output')\n",
        "    elif k == 2:\n",
        "        model.weights_set(torch.tensor([[20., -20.], [-20., 20.]]), torch.tensor([-15., -15.]), 'hidden')\n",
        "        model.weights_set(torch.tensor([[20., 20.]]), torch.tensor([-25.]), 'output')\n",
        "    elif k == 4:\n",
        "        model.weights_set(torch.tensor([[-1., -1.], [-1., 1.], [1., -1.], [1., 1.]]), torch.tensor([0.5, -0.5, -0.5, -1.5]), 'hidden')\n",
        "        model.weights_set(torch.tensor([[0., 1., 1., 0.]]), torch.tensor([-0.5]), 'output')\n",
        "\n",
        "    print(\"Weights and biases:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        print(f\"{name}:\\n{param.data}\")\n",
        "\n",
        "    y_pred = model(x)\n",
        "    loss_value = loss_fn(y_pred, y)\n",
        "    print(f\"Loss: {loss_value.item()}\")\n",
        "\n",
        "    print(\"Truth table:\")\n",
        "    for i in range(4):\n",
        "        print(f\"Input: {x[i].tolist()}, Predicted Output: {round(y_pred[i].item())}, Expected Output: {y[i].item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjfBz2ujgfRH",
        "outputId": "92c2aef3-5d0c-449e-bfd9-d8bfafe85b03"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "k = 1\n",
            "Weights and biases:\n",
            "hidden.weight:\n",
            "tensor([[ 20., -20.]])\n",
            "hidden.bias:\n",
            "tensor([-10.])\n",
            "output.weight:\n",
            "tensor([[20., 20., 20.]])\n",
            "output.bias:\n",
            "tensor([-30.])\n",
            "Loss: 0.5\n",
            "Truth table:\n",
            "Input: [0.0, 0.0], Predicted Output: 0, Expected Output: 0.0\n",
            "Input: [0.0, 1.0], Predicted Output: 0, Expected Output: 1.0\n",
            "Input: [1.0, 0.0], Predicted Output: 1, Expected Output: 1.0\n",
            "Input: [1.0, 1.0], Predicted Output: 1, Expected Output: 0.0\n",
            "\n",
            "k = 2\n",
            "Weights and biases:\n",
            "hidden.weight:\n",
            "tensor([[ 20., -20.],\n",
            "        [-20.,  20.]])\n",
            "hidden.bias:\n",
            "tensor([-15., -15.])\n",
            "output.weight:\n",
            "tensor([[20., 20.]])\n",
            "output.bias:\n",
            "tensor([-25.])\n",
            "Loss: 0.5\n",
            "Truth table:\n",
            "Input: [0.0, 0.0], Predicted Output: 0, Expected Output: 0.0\n",
            "Input: [0.0, 1.0], Predicted Output: 0, Expected Output: 1.0\n",
            "Input: [1.0, 0.0], Predicted Output: 0, Expected Output: 1.0\n",
            "Input: [1.0, 1.0], Predicted Output: 0, Expected Output: 0.0\n",
            "\n",
            "k = 4\n",
            "Weights and biases:\n",
            "hidden.weight:\n",
            "tensor([[-1., -1.],\n",
            "        [-1.,  1.],\n",
            "        [ 1., -1.],\n",
            "        [ 1.,  1.]])\n",
            "hidden.bias:\n",
            "tensor([ 0.5000, -0.5000, -0.5000, -1.5000])\n",
            "output.weight:\n",
            "tensor([[0., 1., 1., 0.]])\n",
            "output.bias:\n",
            "tensor([-0.5000])\n",
            "Loss: 1.961817850054744e-44\n",
            "Truth table:\n",
            "Input: [0.0, 0.0], Predicted Output: 0, Expected Output: 0.0\n",
            "Input: [0.0, 1.0], Predicted Output: 1, Expected Output: 1.0\n",
            "Input: [1.0, 0.0], Predicted Output: 1, Expected Output: 1.0\n",
            "Input: [1.0, 1.0], Predicted Output: 0, Expected Output: 0.0\n"
          ]
        }
      ]
    }
  ]
}